{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-11T13:48:41.454124Z",
     "start_time": "2024-05-11T13:48:41.451405Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T13:48:41.601502Z",
     "start_time": "2024-05-11T13:48:41.455129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get the mnist dataset via keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ],
   "id": "f7238ef5498d020c",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T13:48:52.453922Z",
     "start_time": "2024-05-11T13:48:41.602504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# preprocess the data\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28, 28)))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "model.summary()"
   ],
   "id": "4a56fddbe510c4e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 600us/step - accuracy: 0.8315 - loss: 0.5966 - val_accuracy: 0.9371 - val_loss: 0.2254\n",
      "Epoch 2/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 519us/step - accuracy: 0.9411 - loss: 0.2092 - val_accuracy: 0.9471 - val_loss: 0.1794\n",
      "Epoch 3/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 550us/step - accuracy: 0.9524 - loss: 0.1630 - val_accuracy: 0.9549 - val_loss: 0.1500\n",
      "Epoch 4/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 542us/step - accuracy: 0.9600 - loss: 0.1366 - val_accuracy: 0.9590 - val_loss: 0.1398\n",
      "Epoch 5/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 543us/step - accuracy: 0.9673 - loss: 0.1108 - val_accuracy: 0.9633 - val_loss: 0.1265\n",
      "Epoch 6/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 540us/step - accuracy: 0.9704 - loss: 0.1018 - val_accuracy: 0.9629 - val_loss: 0.1215\n",
      "Epoch 7/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 521us/step - accuracy: 0.9731 - loss: 0.0904 - val_accuracy: 0.9672 - val_loss: 0.1156\n",
      "Epoch 8/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 554us/step - accuracy: 0.9753 - loss: 0.0809 - val_accuracy: 0.9655 - val_loss: 0.1206\n",
      "Epoch 9/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 524us/step - accuracy: 0.9770 - loss: 0.0734 - val_accuracy: 0.9659 - val_loss: 0.1147\n",
      "Epoch 10/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 507us/step - accuracy: 0.9793 - loss: 0.0711 - val_accuracy: 0.9692 - val_loss: 0.1109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_11\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_11 (\u001B[38;5;33mFlatten\u001B[0m)            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m784\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m30\u001B[0m)             │        \u001B[38;5;34m23,550\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m)             │           \u001B[38;5;34m310\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">23,550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">310</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m71,582\u001B[0m (279.62 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">71,582</span> (279.62 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m23,860\u001B[0m (93.20 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,860</span> (93.20 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Optimizer params: \u001B[0m\u001B[38;5;34m47,722\u001B[0m (186.42 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,722</span> (186.42 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T13:50:25.830037Z",
     "start_time": "2024-05-11T13:48:52.453922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the images to [0, 1] range\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    # Flatten layer to transform the 28x28 image into a 784 vector\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    # Hidden layer with 30 neurons, ReLU activation, and L2 regularization\n",
    "    layers.Dense(30, activation='relu', kernel_regularizer=regularizers.l2(5.0)),\n",
    "    # Output layer with 10 neurons, softmax activation, and L2 regularization\n",
    "    layers.Dense(10, activation='softmax', kernel_regularizer=regularizers.l2(5.0))\n",
    "])\n",
    "\n",
    "# Define the optimizer with a specific learning rate\n",
    "optimizer = Adam(learning_rate=0.1)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=30,\n",
    "    batch_size=10,\n",
    "    validation_data=(test_images, test_labels)\n",
    ")\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_loss, train_accuracy = model.evaluate(train_images, train_labels)\n",
    "print(f\"Training Accuracy: {train_accuracy*100:.2f}%\")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n"
   ],
   "id": "611790a242268a98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 519us/step - accuracy: 0.1035 - loss: 6.4261 - val_accuracy: 0.0982 - val_loss: 3.2991\n",
      "Epoch 2/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 509us/step - accuracy: 0.1008 - loss: 3.2561 - val_accuracy: 0.0974 - val_loss: 3.3034\n",
      "Epoch 3/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 504us/step - accuracy: 0.0982 - loss: 3.2597 - val_accuracy: 0.1009 - val_loss: 3.2646\n",
      "Epoch 4/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 504us/step - accuracy: 0.1057 - loss: 3.2584 - val_accuracy: 0.1032 - val_loss: 3.2440\n",
      "Epoch 5/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 504us/step - accuracy: 0.1019 - loss: 3.2590 - val_accuracy: 0.0958 - val_loss: 3.2845\n",
      "Epoch 6/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 501us/step - accuracy: 0.1025 - loss: 3.2626 - val_accuracy: 0.0982 - val_loss: 3.1911\n",
      "Epoch 7/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 505us/step - accuracy: 0.1009 - loss: 3.2597 - val_accuracy: 0.1009 - val_loss: 3.2487\n",
      "Epoch 8/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 506us/step - accuracy: 0.0993 - loss: 3.2603 - val_accuracy: 0.1135 - val_loss: 3.1794\n",
      "Epoch 9/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 505us/step - accuracy: 0.1010 - loss: 3.2576 - val_accuracy: 0.0980 - val_loss: 3.2921\n",
      "Epoch 10/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 504us/step - accuracy: 0.1046 - loss: 3.2597 - val_accuracy: 0.1010 - val_loss: 3.2539\n",
      "Epoch 11/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 505us/step - accuracy: 0.1055 - loss: 3.2577 - val_accuracy: 0.1135 - val_loss: 3.2884\n",
      "Epoch 12/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 506us/step - accuracy: 0.1000 - loss: 3.2595 - val_accuracy: 0.0982 - val_loss: 3.2580\n",
      "Epoch 13/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 507us/step - accuracy: 0.1011 - loss: 3.2578 - val_accuracy: 0.0974 - val_loss: 3.2449\n",
      "Epoch 14/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 505us/step - accuracy: 0.1001 - loss: 3.2595 - val_accuracy: 0.0974 - val_loss: 3.3354\n",
      "Epoch 15/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 507us/step - accuracy: 0.1032 - loss: 3.2599 - val_accuracy: 0.1135 - val_loss: 3.2858\n",
      "Epoch 16/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 503us/step - accuracy: 0.1025 - loss: 3.2586 - val_accuracy: 0.1135 - val_loss: 3.2582\n",
      "Epoch 17/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 503us/step - accuracy: 0.1019 - loss: 3.2584 - val_accuracy: 0.1032 - val_loss: 3.2784\n",
      "Epoch 18/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 506us/step - accuracy: 0.1025 - loss: 3.2576 - val_accuracy: 0.1010 - val_loss: 3.1986\n",
      "Epoch 19/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 500us/step - accuracy: 0.1009 - loss: 3.2581 - val_accuracy: 0.1009 - val_loss: 3.3162\n",
      "Epoch 20/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 503us/step - accuracy: 0.1046 - loss: 3.2592 - val_accuracy: 0.1135 - val_loss: 3.2548\n",
      "Epoch 21/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 504us/step - accuracy: 0.1016 - loss: 3.2590 - val_accuracy: 0.1032 - val_loss: 3.2823\n",
      "Epoch 22/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 505us/step - accuracy: 0.1020 - loss: 3.2590 - val_accuracy: 0.1135 - val_loss: 3.2294\n",
      "Epoch 23/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 504us/step - accuracy: 0.1006 - loss: 3.2588 - val_accuracy: 0.0980 - val_loss: 3.2010\n",
      "Epoch 24/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 511us/step - accuracy: 0.1039 - loss: 3.2595 - val_accuracy: 0.0974 - val_loss: 3.2691\n",
      "Epoch 25/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 500us/step - accuracy: 0.1031 - loss: 3.2573 - val_accuracy: 0.0892 - val_loss: 3.2330\n",
      "Epoch 26/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 498us/step - accuracy: 0.1038 - loss: 3.2588 - val_accuracy: 0.0974 - val_loss: 3.2375\n",
      "Epoch 27/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 513us/step - accuracy: 0.1019 - loss: 3.2579 - val_accuracy: 0.1009 - val_loss: 3.2446\n",
      "Epoch 28/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 519us/step - accuracy: 0.0998 - loss: 3.2589 - val_accuracy: 0.1009 - val_loss: 3.2660\n",
      "Epoch 29/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 513us/step - accuracy: 0.0994 - loss: 3.2600 - val_accuracy: 0.1135 - val_loss: 3.2473\n",
      "Epoch 30/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 504us/step - accuracy: 0.0992 - loss: 3.2589 - val_accuracy: 0.1032 - val_loss: 3.2922\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 408us/step - accuracy: 0.0983 - loss: 3.2937\n",
      "Training Accuracy: 9.93%\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 408us/step - accuracy: 0.1052 - loss: 3.2943\n",
      "Test Accuracy: 10.32%\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T13:52:00.452087Z",
     "start_time": "2024-05-11T13:50:25.831041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the images to [0, 1] range\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    # Flatten layer to transform the 28x28 image into a 784 vector\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    # Hidden layer with 30 neurons, ReLU activation, and L2 regularization\n",
    "    layers.Dense(30, activation='relu', kernel_regularizer=regularizers.l2(0.5)),\n",
    "    # Output layer with 10 neurons, softmax activation, and L2 regularization\n",
    "    layers.Dense(10, activation='softmax', kernel_regularizer=regularizers.l2(0.5))\n",
    "])\n",
    "\n",
    "# Define the optimizer with a specific learning rate\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=30,\n",
    "    batch_size=10,\n",
    "    validation_data=(test_images, test_labels)\n",
    ")\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_loss, train_accuracy = model.evaluate(train_images, train_labels)\n",
    "print(f\"Training Accuracy: {train_accuracy*100:.2f}%\")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n"
   ],
   "id": "885b41892ec1fdd8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 528us/step - accuracy: 0.1167 - loss: 2.5608 - val_accuracy: 0.1135 - val_loss: 2.3141\n",
      "Epoch 2/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 512us/step - accuracy: 0.1088 - loss: 2.3108 - val_accuracy: 0.0980 - val_loss: 2.3047\n",
      "Epoch 3/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 511us/step - accuracy: 0.1066 - loss: 2.3062 - val_accuracy: 0.1028 - val_loss: 2.3044\n",
      "Epoch 4/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 509us/step - accuracy: 0.1094 - loss: 2.3053 - val_accuracy: 0.0980 - val_loss: 2.3060\n",
      "Epoch 5/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 513us/step - accuracy: 0.1096 - loss: 2.3073 - val_accuracy: 0.1135 - val_loss: 2.3043\n",
      "Epoch 6/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 514us/step - accuracy: 0.1081 - loss: 2.3068 - val_accuracy: 0.1028 - val_loss: 2.3057\n",
      "Epoch 7/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 509us/step - accuracy: 0.1100 - loss: 2.3048 - val_accuracy: 0.1009 - val_loss: 2.3063\n",
      "Epoch 8/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 513us/step - accuracy: 0.1054 - loss: 2.3042 - val_accuracy: 0.1010 - val_loss: 2.3039\n",
      "Epoch 9/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 511us/step - accuracy: 0.1079 - loss: 2.3044 - val_accuracy: 0.1028 - val_loss: 2.3048\n",
      "Epoch 10/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 513us/step - accuracy: 0.1037 - loss: 2.3042 - val_accuracy: 0.1135 - val_loss: 2.3033\n",
      "Epoch 11/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 513us/step - accuracy: 0.1067 - loss: 2.3041 - val_accuracy: 0.1135 - val_loss: 2.3026\n",
      "Epoch 12/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 514us/step - accuracy: 0.1069 - loss: 2.3040 - val_accuracy: 0.1135 - val_loss: 2.3024\n",
      "Epoch 13/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 509us/step - accuracy: 0.1087 - loss: 2.3035 - val_accuracy: 0.1135 - val_loss: 2.3083\n",
      "Epoch 14/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 517us/step - accuracy: 0.1091 - loss: 2.3043 - val_accuracy: 0.1135 - val_loss: 2.3049\n",
      "Epoch 15/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 510us/step - accuracy: 0.1046 - loss: 2.3040 - val_accuracy: 0.1135 - val_loss: 2.3027\n",
      "Epoch 16/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 509us/step - accuracy: 0.1054 - loss: 2.3045 - val_accuracy: 0.1135 - val_loss: 2.3041\n",
      "Epoch 17/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 511us/step - accuracy: 0.1086 - loss: 2.3037 - val_accuracy: 0.1028 - val_loss: 2.3028\n",
      "Epoch 18/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 513us/step - accuracy: 0.1045 - loss: 2.3042 - val_accuracy: 0.1009 - val_loss: 2.3036\n",
      "Epoch 19/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 512us/step - accuracy: 0.1084 - loss: 2.3040 - val_accuracy: 0.1135 - val_loss: 2.3029\n",
      "Epoch 20/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 519us/step - accuracy: 0.1073 - loss: 2.3040 - val_accuracy: 0.1135 - val_loss: 2.3019\n",
      "Epoch 21/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 516us/step - accuracy: 0.1036 - loss: 2.3041 - val_accuracy: 0.1135 - val_loss: 2.3023\n",
      "Epoch 22/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 515us/step - accuracy: 0.1072 - loss: 2.3037 - val_accuracy: 0.0974 - val_loss: 2.3042\n",
      "Epoch 23/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 511us/step - accuracy: 0.1043 - loss: 2.3039 - val_accuracy: 0.0974 - val_loss: 2.3037\n",
      "Epoch 24/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 512us/step - accuracy: 0.1075 - loss: 2.3044 - val_accuracy: 0.1135 - val_loss: 2.3057\n",
      "Epoch 25/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 512us/step - accuracy: 0.1081 - loss: 2.3036 - val_accuracy: 0.1010 - val_loss: 2.3044\n",
      "Epoch 26/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 508us/step - accuracy: 0.1042 - loss: 2.3042 - val_accuracy: 0.1009 - val_loss: 2.3045\n",
      "Epoch 27/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 512us/step - accuracy: 0.1097 - loss: 2.3041 - val_accuracy: 0.1135 - val_loss: 2.3024\n",
      "Epoch 28/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 516us/step - accuracy: 0.1084 - loss: 2.3036 - val_accuracy: 0.0958 - val_loss: 2.3037\n",
      "Epoch 29/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 513us/step - accuracy: 0.1080 - loss: 2.3034 - val_accuracy: 0.1135 - val_loss: 2.3037\n",
      "Epoch 30/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 514us/step - accuracy: 0.1066 - loss: 2.3036 - val_accuracy: 0.0980 - val_loss: 2.3045\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 408us/step - accuracy: 0.0986 - loss: 2.3036\n",
      "Training Accuracy: 9.87%\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 403us/step - accuracy: 0.0924 - loss: 2.3052\n",
      "Test Accuracy: 9.80%\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T13:52:13.015885Z",
     "start_time": "2024-05-11T13:52:00.452087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the images to [0, 1] range\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    # Flatten layer to transform the 28x28 image into a 784 vector\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    # Hidden layer with 30 neurons, ReLU activation, and L2 regularization\n",
    "    layers.Dense(30, activation='relu', kernel_regularizer=regularizers.l2()),\n",
    "    # Output layer with 10 neurons, softmax activation, and L2 regularization\n",
    "    layers.Dense(10, activation='softmax', kernel_regularizer=regularizers.l2())\n",
    "])\n",
    "\n",
    "# Define the optimizer with a specific learning rate\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=(test_images, test_labels)\n",
    ")\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_loss, train_accuracy = model.evaluate(train_images, train_labels)\n",
    "print(f\"Training Accuracy: {train_accuracy*100:.2f}%\")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n"
   ],
   "id": "54704d8aeffc39d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 715us/step - accuracy: 0.8335 - loss: 0.9703 - val_accuracy: 0.8801 - val_loss: 0.8009\n",
      "Epoch 2/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 550us/step - accuracy: 0.8609 - loss: 0.8525 - val_accuracy: 0.8815 - val_loss: 0.7967\n",
      "Epoch 3/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 559us/step - accuracy: 0.8645 - loss: 0.8417 - val_accuracy: 0.8833 - val_loss: 0.7846\n",
      "Epoch 4/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 544us/step - accuracy: 0.8661 - loss: 0.8328 - val_accuracy: 0.8866 - val_loss: 0.7764\n",
      "Epoch 5/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 549us/step - accuracy: 0.8661 - loss: 0.8335 - val_accuracy: 0.8458 - val_loss: 0.8451\n",
      "Epoch 6/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 546us/step - accuracy: 0.8653 - loss: 0.8302 - val_accuracy: 0.8855 - val_loss: 0.7758\n",
      "Epoch 7/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 540us/step - accuracy: 0.8688 - loss: 0.8274 - val_accuracy: 0.8735 - val_loss: 0.8062\n",
      "Epoch 8/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 560us/step - accuracy: 0.8649 - loss: 0.8346 - val_accuracy: 0.8628 - val_loss: 0.8197\n",
      "Epoch 9/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 555us/step - accuracy: 0.8679 - loss: 0.8224 - val_accuracy: 0.8507 - val_loss: 0.9039\n",
      "Epoch 10/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 543us/step - accuracy: 0.8703 - loss: 0.8243 - val_accuracy: 0.8813 - val_loss: 0.7831\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 420us/step - accuracy: 0.8746 - loss: 0.7931\n",
      "Training Accuracy: 87.31%\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 423us/step - accuracy: 0.8627 - loss: 0.8366\n",
      "Test Accuracy: 88.13%\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## add another layer with 30 neurons\n",
   "id": "f1cdd874f9937f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T13:52:26.261320Z",
     "start_time": "2024-05-11T13:52:13.015885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Load MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the images to [0, 1] range\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    # Flatten layer to transform the 28x28 image into a 784 vector\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    # Hidden layer with 30 neurons, ReLU activation, and L2 regularization\n",
    "    layers.Dense(30, activation='relu', kernel_regularizer=regularizers.l2()),\n",
    "    layers.Dense(30, activation='relu', kernel_regularizer=regularizers.l2()),\n",
    "    # Output layer with 10 neurons, softmax activation, and L2 regularization\n",
    "    layers.Dense(10, activation='softmax', kernel_regularizer=regularizers.l2())\n",
    "])\n",
    "\n",
    "# Define the optimizer with a specific learning rate\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=(test_images, test_labels)\n",
    ")\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_loss, train_accuracy = model.evaluate(train_images, train_labels)\n",
    "print(f\"Training Accuracy: {train_accuracy*100:.2f}%\")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n"
   ],
   "id": "a84d0de6ba40789e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 658us/step - accuracy: 0.8201 - loss: 1.0891 - val_accuracy: 0.8840 - val_loss: 0.8641\n",
      "Epoch 2/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 592us/step - accuracy: 0.8551 - loss: 0.9325 - val_accuracy: 0.8477 - val_loss: 0.9230\n",
      "Epoch 3/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 579us/step - accuracy: 0.8572 - loss: 0.9117 - val_accuracy: 0.8678 - val_loss: 0.8972\n",
      "Epoch 4/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 582us/step - accuracy: 0.8597 - loss: 0.9040 - val_accuracy: 0.8707 - val_loss: 0.8488\n",
      "Epoch 5/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 592us/step - accuracy: 0.8618 - loss: 0.8951 - val_accuracy: 0.8783 - val_loss: 0.8461\n",
      "Epoch 6/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 587us/step - accuracy: 0.8621 - loss: 0.8889 - val_accuracy: 0.8673 - val_loss: 0.8873\n",
      "Epoch 7/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 593us/step - accuracy: 0.8637 - loss: 0.8886 - val_accuracy: 0.8767 - val_loss: 0.8514\n",
      "Epoch 8/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 596us/step - accuracy: 0.8647 - loss: 0.8860 - val_accuracy: 0.8627 - val_loss: 0.8772\n",
      "Epoch 9/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 583us/step - accuracy: 0.8614 - loss: 0.8858 - val_accuracy: 0.8344 - val_loss: 0.9264\n",
      "Epoch 10/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 593us/step - accuracy: 0.8606 - loss: 0.8919 - val_accuracy: 0.8242 - val_loss: 0.9784\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 422us/step - accuracy: 0.8167 - loss: 0.9932\n",
      "Training Accuracy: 81.41%\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 414us/step - accuracy: 0.7990 - loss: 1.0453\n",
      "Test Accuracy: 82.42%\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## again",
   "id": "c35564111050ba3d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T13:52:39.742633Z",
     "start_time": "2024-05-11T13:52:26.261320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Load MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the images to [0, 1] range\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    # Flatten layer to transform the 28x28 image into a 784 vector\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    # Hidden layer with 30 neurons, ReLU activation, and L2 regularization\n",
    "    layers.Dense(30, activation='relu', kernel_regularizer=regularizers.l2()),\n",
    "    layers.Dense(30, activation='relu', kernel_regularizer=regularizers.l2()),\n",
    "    layers.Dense(30, activation='relu', kernel_regularizer=regularizers.l2()),\n",
    "    # Output layer with 10 neurons, softmax activation, and L2 regularization\n",
    "    layers.Dense(10, activation='softmax', kernel_regularizer=regularizers.l2())\n",
    "])\n",
    "\n",
    "# Define the optimizer with a specific learning rate\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=(test_images, test_labels)\n",
    ")\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_loss, train_accuracy = model.evaluate(train_images, train_labels)\n",
    "print(f\"Training Accuracy: {train_accuracy*100:.2f}%\")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n"
   ],
   "id": "d3b144e31bb8d969",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 648us/step - accuracy: 0.7790 - loss: 1.2149 - val_accuracy: 0.8494 - val_loss: 0.9984\n",
      "Epoch 2/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 586us/step - accuracy: 0.8440 - loss: 0.9829 - val_accuracy: 0.8538 - val_loss: 0.9444\n",
      "Epoch 3/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 594us/step - accuracy: 0.8382 - loss: 0.9795 - val_accuracy: 0.8591 - val_loss: 0.9143\n",
      "Epoch 4/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 592us/step - accuracy: 0.8445 - loss: 0.9588 - val_accuracy: 0.8622 - val_loss: 0.9135\n",
      "Epoch 5/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 601us/step - accuracy: 0.8403 - loss: 0.9671 - val_accuracy: 0.8541 - val_loss: 0.9439\n",
      "Epoch 6/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 591us/step - accuracy: 0.8405 - loss: 0.9631 - val_accuracy: 0.8486 - val_loss: 0.9247\n",
      "Epoch 7/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 613us/step - accuracy: 0.8415 - loss: 0.9526 - val_accuracy: 0.8552 - val_loss: 0.9137\n",
      "Epoch 8/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 584us/step - accuracy: 0.8454 - loss: 0.9395 - val_accuracy: 0.8572 - val_loss: 0.9069\n",
      "Epoch 9/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 587us/step - accuracy: 0.8473 - loss: 0.9388 - val_accuracy: 0.8566 - val_loss: 0.8931\n",
      "Epoch 10/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 586us/step - accuracy: 0.8441 - loss: 0.9448 - val_accuracy: 0.8508 - val_loss: 0.9382\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 436us/step - accuracy: 0.8434 - loss: 0.9584\n",
      "Training Accuracy: 84.43%\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 435us/step - accuracy: 0.8443 - loss: 0.9640\n",
      "Test Accuracy: 85.08%\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T13:52:39.745001Z",
     "start_time": "2024-05-11T13:52:39.742633Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "96de9a2bcae42240",
   "outputs": [],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
