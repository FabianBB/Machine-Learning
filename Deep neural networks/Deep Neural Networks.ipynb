{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:43.119398Z",
     "start_time": "2024-05-11T15:01:43.116776Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:45.811641Z",
     "start_time": "2024-05-11T15:01:43.120408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get the mnist dataset via keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ],
   "id": "f7238ef5498d020c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:01:56.826307Z",
     "start_time": "2024-05-11T15:01:45.812646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# preprocess the data\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28, 28)))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "model.summary()"
   ],
   "id": "4a56fddbe510c4e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\venv\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 594us/step - accuracy: 0.8275 - loss: 0.6064 - val_accuracy: 0.9355 - val_loss: 0.2177\n",
      "Epoch 2/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 537us/step - accuracy: 0.9422 - loss: 0.2059 - val_accuracy: 0.9488 - val_loss: 0.1798\n",
      "Epoch 3/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 543us/step - accuracy: 0.9526 - loss: 0.1632 - val_accuracy: 0.9552 - val_loss: 0.1538\n",
      "Epoch 4/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 539us/step - accuracy: 0.9591 - loss: 0.1392 - val_accuracy: 0.9602 - val_loss: 0.1373\n",
      "Epoch 5/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 535us/step - accuracy: 0.9655 - loss: 0.1222 - val_accuracy: 0.9581 - val_loss: 0.1392\n",
      "Epoch 6/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 529us/step - accuracy: 0.9681 - loss: 0.1091 - val_accuracy: 0.9620 - val_loss: 0.1278\n",
      "Epoch 7/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 561us/step - accuracy: 0.9706 - loss: 0.0959 - val_accuracy: 0.9641 - val_loss: 0.1197\n",
      "Epoch 8/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 537us/step - accuracy: 0.9725 - loss: 0.0897 - val_accuracy: 0.9661 - val_loss: 0.1136\n",
      "Epoch 9/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 531us/step - accuracy: 0.9750 - loss: 0.0838 - val_accuracy: 0.9656 - val_loss: 0.1184\n",
      "Epoch 10/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 523us/step - accuracy: 0.9770 - loss: 0.0756 - val_accuracy: 0.9674 - val_loss: 0.1115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001B[38;5;33mFlatten\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m784\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m30\u001B[0m)             │        \u001B[38;5;34m23,550\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m)             │           \u001B[38;5;34m310\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">23,550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">310</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m71,582\u001B[0m (279.62 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">71,582</span> (279.62 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m23,860\u001B[0m (93.20 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,860</span> (93.20 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Optimizer params: \u001B[0m\u001B[38;5;34m47,722\u001B[0m (186.42 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,722</span> (186.42 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:03:31.476442Z",
     "start_time": "2024-05-11T15:01:56.826307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the images to [0, 1] range\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    # Flatten layer to transform the 28x28 image into a 784 vector\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    # Hidden layer with 30 neurons, ReLU activation, and L2 regularization\n",
    "    layers.Dense(30, activation='relu', kernel_regularizer=regularizers.l2(5.0)),\n",
    "    # Output layer with 10 neurons, softmax activation, and L2 regularization\n",
    "    layers.Dense(10, activation='softmax', kernel_regularizer=regularizers.l2(5.0))\n",
    "])\n",
    "\n",
    "# Define the optimizer with a specific learning rate\n",
    "optimizer = Adam(learning_rate=0.1)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=30,\n",
    "    batch_size=10,\n",
    "    validation_data=(test_images, test_labels)\n",
    ")\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_loss, train_accuracy = model.evaluate(train_images, train_labels)\n",
    "print(f\"Training Accuracy: {train_accuracy*100:.2f}%\")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n"
   ],
   "id": "611790a242268a98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 521us/step - accuracy: 0.1024 - loss: 6.4253 - val_accuracy: 0.1028 - val_loss: 3.2760\n",
      "Epoch 2/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 514us/step - accuracy: 0.1007 - loss: 3.2510 - val_accuracy: 0.0980 - val_loss: 3.2883\n",
      "Epoch 3/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 515us/step - accuracy: 0.1024 - loss: 3.2539 - val_accuracy: 0.0958 - val_loss: 3.2853\n",
      "Epoch 4/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 511us/step - accuracy: 0.1039 - loss: 3.2542 - val_accuracy: 0.0980 - val_loss: 3.2598\n",
      "Epoch 5/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 517us/step - accuracy: 0.1024 - loss: 3.2543 - val_accuracy: 0.1028 - val_loss: 3.2178\n",
      "Epoch 6/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 514us/step - accuracy: 0.1022 - loss: 3.2551 - val_accuracy: 0.0958 - val_loss: 3.2172\n",
      "Epoch 7/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 515us/step - accuracy: 0.1019 - loss: 3.2538 - val_accuracy: 0.1009 - val_loss: 3.2316\n",
      "Epoch 8/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 514us/step - accuracy: 0.1024 - loss: 3.2528 - val_accuracy: 0.0974 - val_loss: 3.2494\n",
      "Epoch 9/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 512us/step - accuracy: 0.1018 - loss: 3.2531 - val_accuracy: 0.0892 - val_loss: 3.3307\n",
      "Epoch 10/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 510us/step - accuracy: 0.1018 - loss: 3.2527 - val_accuracy: 0.1028 - val_loss: 3.2715\n",
      "Epoch 11/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 510us/step - accuracy: 0.1015 - loss: 3.2553 - val_accuracy: 0.1009 - val_loss: 3.2034\n",
      "Epoch 12/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 517us/step - accuracy: 0.1030 - loss: 3.2536 - val_accuracy: 0.1010 - val_loss: 3.2503\n",
      "Epoch 13/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 519us/step - accuracy: 0.1025 - loss: 3.2536 - val_accuracy: 0.1028 - val_loss: 3.2041\n",
      "Epoch 14/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 517us/step - accuracy: 0.1042 - loss: 3.2546 - val_accuracy: 0.1032 - val_loss: 3.3249\n",
      "Epoch 15/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 508us/step - accuracy: 0.1057 - loss: 3.2539 - val_accuracy: 0.1032 - val_loss: 3.2380\n",
      "Epoch 16/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 517us/step - accuracy: 0.1007 - loss: 3.2531 - val_accuracy: 0.1009 - val_loss: 3.2599\n",
      "Epoch 17/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 515us/step - accuracy: 0.1021 - loss: 3.2544 - val_accuracy: 0.0958 - val_loss: 3.2889\n",
      "Epoch 18/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 518us/step - accuracy: 0.1031 - loss: 3.2554 - val_accuracy: 0.0974 - val_loss: 3.2692\n",
      "Epoch 19/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 526us/step - accuracy: 0.1032 - loss: 3.2529 - val_accuracy: 0.1009 - val_loss: 3.2016\n",
      "Epoch 20/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 499us/step - accuracy: 0.0998 - loss: 3.2549 - val_accuracy: 0.0974 - val_loss: 3.1890\n",
      "Epoch 21/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 507us/step - accuracy: 0.1064 - loss: 3.2535 - val_accuracy: 0.0980 - val_loss: 3.3231\n",
      "Epoch 22/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 506us/step - accuracy: 0.1023 - loss: 3.2538 - val_accuracy: 0.0982 - val_loss: 3.3164\n",
      "Epoch 23/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 502us/step - accuracy: 0.1009 - loss: 3.2549 - val_accuracy: 0.1135 - val_loss: 3.1834\n",
      "Epoch 24/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 513us/step - accuracy: 0.1012 - loss: 3.2548 - val_accuracy: 0.1010 - val_loss: 3.2806\n",
      "Epoch 25/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 507us/step - accuracy: 0.1035 - loss: 3.2544 - val_accuracy: 0.0980 - val_loss: 3.2023\n",
      "Epoch 26/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 513us/step - accuracy: 0.1027 - loss: 3.2526 - val_accuracy: 0.0974 - val_loss: 3.2878\n",
      "Epoch 27/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 513us/step - accuracy: 0.1013 - loss: 3.2522 - val_accuracy: 0.1010 - val_loss: 3.2686\n",
      "Epoch 28/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 511us/step - accuracy: 0.1002 - loss: 3.2527 - val_accuracy: 0.1135 - val_loss: 3.2778\n",
      "Epoch 29/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 508us/step - accuracy: 0.1015 - loss: 3.2551 - val_accuracy: 0.0974 - val_loss: 3.1934\n",
      "Epoch 30/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 511us/step - accuracy: 0.1039 - loss: 3.2540 - val_accuracy: 0.0982 - val_loss: 3.2203\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 411us/step - accuracy: 0.0986 - loss: 3.2216\n",
      "Training Accuracy: 9.74%\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 396us/step - accuracy: 0.1044 - loss: 3.2205\n",
      "Test Accuracy: 9.82%\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:05:05.070272Z",
     "start_time": "2024-05-11T15:03:31.476442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the images to [0, 1] range\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    # Flatten layer to transform the 28x28 image into a 784 vector\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    # Hidden layer with 30 neurons, ReLU activation, and L2 regularization\n",
    "    layers.Dense(30, activation='relu', kernel_regularizer=regularizers.l2(0.5)),\n",
    "    # Output layer with 10 neurons, softmax activation, and L2 regularization\n",
    "    layers.Dense(10, activation='softmax', kernel_regularizer=regularizers.l2(0.5))\n",
    "])\n",
    "\n",
    "# Define the optimizer with a specific learning rate\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=30,\n",
    "    batch_size=10,\n",
    "    validation_data=(test_images, test_labels)\n",
    ")\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_loss, train_accuracy = model.evaluate(train_images, train_labels)\n",
    "print(f\"Training Accuracy: {train_accuracy*100:.2f}%\")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n"
   ],
   "id": "885b41892ec1fdd8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 522us/step - accuracy: 0.1130 - loss: 2.5576 - val_accuracy: 0.1135 - val_loss: 2.3105\n",
      "Epoch 2/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 508us/step - accuracy: 0.1089 - loss: 2.3195 - val_accuracy: 0.1028 - val_loss: 2.3043\n",
      "Epoch 3/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 511us/step - accuracy: 0.1073 - loss: 2.3079 - val_accuracy: 0.1135 - val_loss: 2.3033\n",
      "Epoch 4/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 511us/step - accuracy: 0.1126 - loss: 2.3081 - val_accuracy: 0.1028 - val_loss: 2.3030\n",
      "Epoch 5/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 511us/step - accuracy: 0.1056 - loss: 2.3042 - val_accuracy: 0.1135 - val_loss: 2.3021\n",
      "Epoch 6/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 511us/step - accuracy: 0.1092 - loss: 2.3042 - val_accuracy: 0.1135 - val_loss: 2.3032\n",
      "Epoch 7/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 512us/step - accuracy: 0.1040 - loss: 2.3046 - val_accuracy: 0.1135 - val_loss: 2.3025\n",
      "Epoch 8/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 505us/step - accuracy: 0.1050 - loss: 2.3045 - val_accuracy: 0.1135 - val_loss: 2.3044\n",
      "Epoch 9/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 498us/step - accuracy: 0.1067 - loss: 2.3046 - val_accuracy: 0.1135 - val_loss: 2.3027\n",
      "Epoch 10/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 504us/step - accuracy: 0.1083 - loss: 2.3038 - val_accuracy: 0.1135 - val_loss: 2.3036\n",
      "Epoch 11/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 505us/step - accuracy: 0.1055 - loss: 2.3042 - val_accuracy: 0.1135 - val_loss: 2.3038\n",
      "Epoch 12/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 498us/step - accuracy: 0.1025 - loss: 2.3045 - val_accuracy: 0.1135 - val_loss: 2.3031\n",
      "Epoch 13/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 502us/step - accuracy: 0.1107 - loss: 2.3035 - val_accuracy: 0.1028 - val_loss: 2.3042\n",
      "Epoch 14/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 496us/step - accuracy: 0.1068 - loss: 2.3041 - val_accuracy: 0.1135 - val_loss: 2.3031\n",
      "Epoch 15/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 492us/step - accuracy: 0.1102 - loss: 2.3033 - val_accuracy: 0.1135 - val_loss: 2.3023\n",
      "Epoch 16/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 514us/step - accuracy: 0.1069 - loss: 2.3042 - val_accuracy: 0.1010 - val_loss: 2.3035\n",
      "Epoch 17/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 584us/step - accuracy: 0.1073 - loss: 2.3037 - val_accuracy: 0.1028 - val_loss: 2.3064\n",
      "Epoch 18/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 510us/step - accuracy: 0.1065 - loss: 2.3043 - val_accuracy: 0.0958 - val_loss: 2.3054\n",
      "Epoch 19/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 509us/step - accuracy: 0.1061 - loss: 2.3042 - val_accuracy: 0.1135 - val_loss: 2.3043\n",
      "Epoch 20/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 501us/step - accuracy: 0.1084 - loss: 2.3040 - val_accuracy: 0.1010 - val_loss: 2.3054\n",
      "Epoch 21/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 493us/step - accuracy: 0.1042 - loss: 2.3042 - val_accuracy: 0.0974 - val_loss: 2.3034\n",
      "Epoch 22/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 501us/step - accuracy: 0.1041 - loss: 2.3044 - val_accuracy: 0.1028 - val_loss: 2.3035\n",
      "Epoch 23/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 504us/step - accuracy: 0.1058 - loss: 2.3042 - val_accuracy: 0.1135 - val_loss: 2.3031\n",
      "Epoch 24/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 504us/step - accuracy: 0.1085 - loss: 2.3036 - val_accuracy: 0.1135 - val_loss: 2.3020\n",
      "Epoch 25/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 497us/step - accuracy: 0.1087 - loss: 2.3041 - val_accuracy: 0.1135 - val_loss: 2.3019\n",
      "Epoch 26/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 496us/step - accuracy: 0.1047 - loss: 2.3045 - val_accuracy: 0.1135 - val_loss: 2.3022\n",
      "Epoch 27/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 501us/step - accuracy: 0.1100 - loss: 2.3035 - val_accuracy: 0.1135 - val_loss: 2.3044\n",
      "Epoch 28/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 499us/step - accuracy: 0.1088 - loss: 2.3039 - val_accuracy: 0.1135 - val_loss: 2.3048\n",
      "Epoch 29/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 501us/step - accuracy: 0.1078 - loss: 2.3043 - val_accuracy: 0.1135 - val_loss: 2.3043\n",
      "Epoch 30/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 504us/step - accuracy: 0.1071 - loss: 2.3047 - val_accuracy: 0.1010 - val_loss: 2.3039\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 410us/step - accuracy: 0.1022 - loss: 2.3039\n",
      "Training Accuracy: 10.22%\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 409us/step - accuracy: 0.1009 - loss: 2.3044\n",
      "Test Accuracy: 10.10%\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:05:17.374569Z",
     "start_time": "2024-05-11T15:05:05.070272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the images to [0, 1] range\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    # Flatten layer to transform the 28x28 image into a 784 vector\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    # Hidden layer with 30 neurons, ReLU activation, and L2 regularization\n",
    "    layers.Dense(30, activation='relu', kernel_regularizer=regularizers.l2()),\n",
    "    # Output layer with 10 neurons, softmax activation, and L2 regularization\n",
    "    layers.Dense(10, activation='softmax', kernel_regularizer=regularizers.l2())\n",
    "])\n",
    "\n",
    "# Define the optimizer with a specific learning rate\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=(test_images, test_labels)\n",
    ")\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_loss, train_accuracy = model.evaluate(train_images, train_labels)\n",
    "print(f\"Training Accuracy: {train_accuracy*100:.2f}%\")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n"
   ],
   "id": "54704d8aeffc39d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 599us/step - accuracy: 0.8335 - loss: 0.9771 - val_accuracy: 0.8838 - val_loss: 0.7977\n",
      "Epoch 2/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 542us/step - accuracy: 0.8627 - loss: 0.8634 - val_accuracy: 0.8634 - val_loss: 0.8649\n",
      "Epoch 3/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 546us/step - accuracy: 0.8658 - loss: 0.8456 - val_accuracy: 0.8669 - val_loss: 0.8419\n",
      "Epoch 4/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 544us/step - accuracy: 0.8652 - loss: 0.8450 - val_accuracy: 0.8678 - val_loss: 0.8323\n",
      "Epoch 5/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 546us/step - accuracy: 0.8662 - loss: 0.8350 - val_accuracy: 0.8816 - val_loss: 0.7748\n",
      "Epoch 6/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 543us/step - accuracy: 0.8660 - loss: 0.8339 - val_accuracy: 0.8910 - val_loss: 0.7704\n",
      "Epoch 7/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 544us/step - accuracy: 0.8653 - loss: 0.8331 - val_accuracy: 0.8682 - val_loss: 0.8158\n",
      "Epoch 8/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 548us/step - accuracy: 0.8687 - loss: 0.8275 - val_accuracy: 0.8906 - val_loss: 0.7659\n",
      "Epoch 9/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 548us/step - accuracy: 0.8675 - loss: 0.8327 - val_accuracy: 0.8908 - val_loss: 0.7763\n",
      "Epoch 10/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 551us/step - accuracy: 0.8694 - loss: 0.8287 - val_accuracy: 0.8871 - val_loss: 0.7919\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 412us/step - accuracy: 0.8787 - loss: 0.8068\n",
      "Training Accuracy: 87.80%\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 418us/step - accuracy: 0.8723 - loss: 0.8461\n",
      "Test Accuracy: 88.71%\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## add another layer with 30 neurons\n",
   "id": "f1cdd874f9937f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:05:30.271903Z",
     "start_time": "2024-05-11T15:05:17.374569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Load MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the images to [0, 1] range\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    # Flatten layer to transform the 28x28 image into a 784 vector\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    # Hidden layer with 30 neurons, ReLU activation, and L2 regularization\n",
    "    layers.Dense(30, activation='relu', kernel_regularizer=regularizers.l2()),\n",
    "    layers.Dense(30, activation='relu', kernel_regularizer=regularizers.l2()),\n",
    "    # Output layer with 10 neurons, softmax activation, and L2 regularization\n",
    "    layers.Dense(10, activation='softmax', kernel_regularizer=regularizers.l2())\n",
    "])\n",
    "\n",
    "# Define the optimizer with a specific learning rate\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=(test_images, test_labels)\n",
    ")\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_loss, train_accuracy = model.evaluate(train_images, train_labels)\n",
    "print(f\"Training Accuracy: {train_accuracy*100:.2f}%\")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n"
   ],
   "id": "a84d0de6ba40789e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 629us/step - accuracy: 0.8153 - loss: 1.1094 - val_accuracy: 0.8644 - val_loss: 0.9234\n",
      "Epoch 2/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 565us/step - accuracy: 0.8539 - loss: 0.9354 - val_accuracy: 0.8725 - val_loss: 0.8862\n",
      "Epoch 3/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 563us/step - accuracy: 0.8623 - loss: 0.8953 - val_accuracy: 0.8491 - val_loss: 0.9606\n",
      "Epoch 4/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 570us/step - accuracy: 0.8615 - loss: 0.8925 - val_accuracy: 0.8601 - val_loss: 0.8725\n",
      "Epoch 5/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 566us/step - accuracy: 0.8636 - loss: 0.8853 - val_accuracy: 0.8701 - val_loss: 0.8802\n",
      "Epoch 6/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 573us/step - accuracy: 0.8623 - loss: 0.8957 - val_accuracy: 0.8752 - val_loss: 0.8676\n",
      "Epoch 7/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 573us/step - accuracy: 0.8626 - loss: 0.8899 - val_accuracy: 0.8160 - val_loss: 0.9723\n",
      "Epoch 8/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 574us/step - accuracy: 0.8618 - loss: 0.8912 - val_accuracy: 0.8791 - val_loss: 0.8424\n",
      "Epoch 9/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 575us/step - accuracy: 0.8635 - loss: 0.8858 - val_accuracy: 0.8635 - val_loss: 0.8993\n",
      "Epoch 10/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 564us/step - accuracy: 0.8649 - loss: 0.8838 - val_accuracy: 0.8443 - val_loss: 0.9045\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 430us/step - accuracy: 0.8459 - loss: 0.9118\n",
      "Training Accuracy: 84.56%\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 426us/step - accuracy: 0.8181 - loss: 0.9698\n",
      "Test Accuracy: 84.43%\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## again",
   "id": "c35564111050ba3d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:05:43.864995Z",
     "start_time": "2024-05-11T15:05:30.272909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Load MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the images to [0, 1] range\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    # Flatten layer to transform the 28x28 image into a 784 vector\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    # Hidden layer with 30 neurons, ReLU activation, and L2 regularization\n",
    "    layers.Dense(30, activation='relu', kernel_regularizer=regularizers.l2()),\n",
    "    layers.Dense(30, activation='relu', kernel_regularizer=regularizers.l2()),\n",
    "    layers.Dense(30, activation='relu', kernel_regularizer=regularizers.l2()),\n",
    "    # Output layer with 10 neurons, softmax activation, and L2 regularization\n",
    "    layers.Dense(10, activation='softmax', kernel_regularizer=regularizers.l2())\n",
    "])\n",
    "\n",
    "# Define the optimizer with a specific learning rate\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=(test_images, test_labels)\n",
    ")\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_loss, train_accuracy = model.evaluate(train_images, train_labels)\n",
    "print(f\"Training Accuracy: {train_accuracy*100:.2f}%\")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n"
   ],
   "id": "d3b144e31bb8d969",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 641us/step - accuracy: 0.7871 - loss: 1.2159 - val_accuracy: 0.8697 - val_loss: 0.9680\n",
      "Epoch 2/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 580us/step - accuracy: 0.8471 - loss: 0.9993 - val_accuracy: 0.8454 - val_loss: 0.9701\n",
      "Epoch 3/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 580us/step - accuracy: 0.8428 - loss: 0.9877 - val_accuracy: 0.8548 - val_loss: 0.9505\n",
      "Epoch 4/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 591us/step - accuracy: 0.8474 - loss: 0.9778 - val_accuracy: 0.8683 - val_loss: 0.9105\n",
      "Epoch 5/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 595us/step - accuracy: 0.8469 - loss: 0.9782 - val_accuracy: 0.8582 - val_loss: 0.9528\n",
      "Epoch 6/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 595us/step - accuracy: 0.8510 - loss: 0.9607 - val_accuracy: 0.8804 - val_loss: 0.9009\n",
      "Epoch 7/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 590us/step - accuracy: 0.8502 - loss: 0.9673 - val_accuracy: 0.8284 - val_loss: 0.9816\n",
      "Epoch 8/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 602us/step - accuracy: 0.8519 - loss: 0.9510 - val_accuracy: 0.8651 - val_loss: 0.9085\n",
      "Epoch 9/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 582us/step - accuracy: 0.8487 - loss: 0.9558 - val_accuracy: 0.8221 - val_loss: 1.0440\n",
      "Epoch 10/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 599us/step - accuracy: 0.8525 - loss: 0.9473 - val_accuracy: 0.8699 - val_loss: 0.9020\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 450us/step - accuracy: 0.8679 - loss: 0.9131\n",
      "Training Accuracy: 86.60%\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 435us/step - accuracy: 0.8525 - loss: 0.9509\n",
      "Test Accuracy: 86.99%\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T15:12:47.855318Z",
     "start_time": "2024-05-11T15:11:04.078401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the images to [0, 1] range\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    # Flatten layer to transform the 28x28 image into a 784 vector\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    # Deepen the network with more layers and use LeakyReLU for activation\n",
    "    layers.Dense(30, ), LeakyReLU(negative_slope=0.01),\n",
    "    layers.Dense(30, ), LeakyReLU(negative_slope=0.01),\n",
    "    layers.Dense(30, ), LeakyReLU(negative_slope=0.01),\n",
    "    # Output layer with 10 neurons, softmax activation, and L2 regularization\n",
    "    layers.Dense(10, activation='softmax', kernel_regularizer=regularizers.l2())\n",
    "])\n",
    "\n",
    "# Define the optimizer with a specific learning rate\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=30,\n",
    "    batch_size=10,\n",
    "    validation_data=(test_images, test_labels)\n",
    ")\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_loss, train_accuracy = model.evaluate(train_images, train_labels)\n",
    "print(f\"Training Accuracy: {train_accuracy*100:.2f}%\")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n"
   ],
   "id": "96de9a2bcae42240",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 566us/step - accuracy: 0.8492 - loss: 0.5531 - val_accuracy: 0.9285 - val_loss: 0.3374\n",
      "Epoch 2/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 556us/step - accuracy: 0.9288 - loss: 0.3054 - val_accuracy: 0.9289 - val_loss: 0.3253\n",
      "Epoch 3/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 557us/step - accuracy: 0.9415 - loss: 0.2615 - val_accuracy: 0.9489 - val_loss: 0.2343\n",
      "Epoch 4/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 568us/step - accuracy: 0.9460 - loss: 0.2435 - val_accuracy: 0.9299 - val_loss: 0.3061\n",
      "Epoch 5/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 562us/step - accuracy: 0.9509 - loss: 0.2245 - val_accuracy: 0.9480 - val_loss: 0.2444\n",
      "Epoch 6/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 563us/step - accuracy: 0.9523 - loss: 0.2159 - val_accuracy: 0.9392 - val_loss: 0.2692\n",
      "Epoch 7/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 561us/step - accuracy: 0.9541 - loss: 0.2229 - val_accuracy: 0.9497 - val_loss: 0.2463\n",
      "Epoch 8/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 556us/step - accuracy: 0.9553 - loss: 0.2147 - val_accuracy: 0.9433 - val_loss: 0.3550\n",
      "Epoch 9/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 560us/step - accuracy: 0.9547 - loss: 0.2203 - val_accuracy: 0.9596 - val_loss: 0.2065\n",
      "Epoch 10/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 561us/step - accuracy: 0.9581 - loss: 0.1949 - val_accuracy: 0.9534 - val_loss: 0.2137\n",
      "Epoch 11/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 563us/step - accuracy: 0.9588 - loss: 0.2028 - val_accuracy: 0.9417 - val_loss: 0.4615\n",
      "Epoch 12/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 562us/step - accuracy: 0.9587 - loss: 0.2021 - val_accuracy: 0.9579 - val_loss: 0.2047\n",
      "Epoch 13/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 563us/step - accuracy: 0.9608 - loss: 0.1879 - val_accuracy: 0.9528 - val_loss: 0.2167\n",
      "Epoch 14/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 558us/step - accuracy: 0.9600 - loss: 0.2104 - val_accuracy: 0.9608 - val_loss: 0.2074\n",
      "Epoch 15/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 569us/step - accuracy: 0.9624 - loss: 0.1735 - val_accuracy: 0.9349 - val_loss: 0.3514\n",
      "Epoch 16/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 567us/step - accuracy: 0.9602 - loss: 0.1970 - val_accuracy: 0.9583 - val_loss: 0.2301\n",
      "Epoch 17/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 562us/step - accuracy: 0.9646 - loss: 0.1665 - val_accuracy: 0.9534 - val_loss: 0.2568\n",
      "Epoch 18/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 558us/step - accuracy: 0.9601 - loss: 0.2050 - val_accuracy: 0.9543 - val_loss: 0.3081\n",
      "Epoch 19/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 559us/step - accuracy: 0.9622 - loss: 0.1926 - val_accuracy: 0.9563 - val_loss: 0.2641\n",
      "Epoch 20/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 562us/step - accuracy: 0.9626 - loss: 0.1932 - val_accuracy: 0.9556 - val_loss: 0.2519\n",
      "Epoch 21/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 561us/step - accuracy: 0.9618 - loss: 0.1825 - val_accuracy: 0.9570 - val_loss: 0.3485\n",
      "Epoch 22/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 563us/step - accuracy: 0.9609 - loss: 0.1958 - val_accuracy: 0.9552 - val_loss: 0.2752\n",
      "Epoch 23/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 559us/step - accuracy: 0.9638 - loss: 0.1816 - val_accuracy: 0.9471 - val_loss: 0.3121\n",
      "Epoch 24/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 562us/step - accuracy: 0.9626 - loss: 0.1856 - val_accuracy: 0.9511 - val_loss: 0.3214\n",
      "Epoch 25/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 563us/step - accuracy: 0.9622 - loss: 0.1960 - val_accuracy: 0.9482 - val_loss: 0.3709\n",
      "Epoch 26/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 561us/step - accuracy: 0.9630 - loss: 0.2003 - val_accuracy: 0.9324 - val_loss: 0.3743\n",
      "Epoch 27/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 565us/step - accuracy: 0.9584 - loss: 0.2238 - val_accuracy: 0.9453 - val_loss: 0.3367\n",
      "Epoch 28/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 562us/step - accuracy: 0.9625 - loss: 0.2084 - val_accuracy: 0.9547 - val_loss: 0.2725\n",
      "Epoch 29/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 563us/step - accuracy: 0.9585 - loss: 0.2284 - val_accuracy: 0.9464 - val_loss: 0.3452\n",
      "Epoch 30/30\n",
      "\u001B[1m6000/6000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 560us/step - accuracy: 0.9625 - loss: 0.1995 - val_accuracy: 0.9434 - val_loss: 0.3109\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 438us/step - accuracy: 0.9580 - loss: 0.1839\n",
      "Training Accuracy: 95.81%\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 432us/step - accuracy: 0.9343 - loss: 0.3852\n",
      "Test Accuracy: 94.34%\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "33beaa1b2175da36"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
